import torch
import whisper
import os
from pathlib import Path
from tqdm import tqdm
import json
import time

# === CONFIGURATION ===
DOSSIER_VIDEOS = "videos"
DOSSIER_JSON = "json"
DUREE_BLOC_SECONDES = 30
TIMEOUT_PAR_VIDEO = 1200  # ‚è±Ô∏è 20 minutes max par vid√©o

# Pr√©paration des dossiers
os.makedirs(DOSSIER_JSON, exist_ok=True)

# Charger Whisper
print("üîÅ Chargement du mod√®le Whisper...")
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model("base", device=DEVICE)
print(f"‚úÖ Mod√®le charg√© sur : {DEVICE}")

# R√©cup√©rer les vid√©os
videos = list(Path(DOSSIER_VIDEOS).glob("*.mp4"))
print("üéûÔ∏è Vid√©os trouv√©es :", [v.name for v in videos])

# Transcription vid√©o par vid√©o
for chemin_video in tqdm(videos, desc="üìº Transcription en cours"):
    nom_base = chemin_video.stem
    json_sortie = Path(DOSSIER_JSON) / f"{nom_base}.json"
    
    if json_sortie.exists():
        print(f"‚úÖ D√©j√† trait√© : {json_sortie.name}")
        continue

    print(f"üîä Transcription : {chemin_video.name}")
    try:
        start_time = time.time()
        result = model.transcribe(str(chemin_video), language="fr", verbose=False, fp16=(DEVICE=="cuda"))
        elapsed = time.time() - start_time

        if elapsed > TIMEOUT_PAR_VIDEO:
            print(f"‚ö†Ô∏è Temps d√©pass√© pour {chemin_video.name}, ignor√©e.")
            continue

        with open(json_sortie, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"‚úÖ Sauvegard√© : {json_sortie.name} en {round(elapsed/60, 1)} min")

    except KeyboardInterrupt:
        print("‚õî Interruption manuelle üñêÔ∏è")
        break
    except Exception as e:
        print(f"‚ùå Erreur sur {chemin_video.name} : {e}")
